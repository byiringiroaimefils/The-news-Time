[
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "openpyxl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openpyxl",
        "description": "openpyxl",
        "detail": "openpyxl",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "url = \"https://www.newtimes.co.rw\"\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, 'html.parser')\ntitle_articles= soup.find_all(\"h1\", class_=\"title article\")\narticle_bodies= soup.find_all(\"div\", class_=\"article-body\")\nworkbook = openpyxl.Workbook()\nsheet = workbook.active\nsheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "response = requests.get(url)\nsoup = BeautifulSoup(response.content, 'html.parser')\ntitle_articles= soup.find_all(\"h1\", class_=\"title article\")\narticle_bodies= soup.find_all(\"div\", class_=\"article-body\")\nworkbook = openpyxl.Workbook()\nsheet = workbook.active\nsheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "soup",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "soup = BeautifulSoup(response.content, 'html.parser')\ntitle_articles= soup.find_all(\"h1\", class_=\"title article\")\narticle_bodies= soup.find_all(\"div\", class_=\"article-body\")\nworkbook = openpyxl.Workbook()\nsheet = workbook.active\nsheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())\n        sheet.cell(row=i+1, column=2, value=p.text.strip())",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "workbook",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "workbook = openpyxl.Workbook()\nsheet = workbook.active\nsheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())\n        sheet.cell(row=i+1, column=2, value=p.text.strip())\nworkbook.save('TheNew_data.xlsx')\nprint(\"Data has been extracted \")",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "sheet",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "sheet = workbook.active\nsheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())\n        sheet.cell(row=i+1, column=2, value=p.text.strip())\nworkbook.save('TheNew_data.xlsx')\nprint(\"Data has been extracted \")",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "sheet['A1']",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "sheet['A1'] = 'Title Article'\nsheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())\n        sheet.cell(row=i+1, column=2, value=p.text.strip())\nworkbook.save('TheNew_data.xlsx')\nprint(\"Data has been extracted \")",
        "detail": "DataExtraction",
        "documentation": {}
    },
    {
        "label": "sheet['B1']",
        "kind": 5,
        "importPath": "DataExtraction",
        "description": "DataExtraction",
        "peekOfCode": "sheet['B1'] = 'article Body'\nfor i, p in  enumerate(zip(title_articles, article_bodies), start=2) :\n        sheet.cell(row=i+1, column=1, value=p.text.strip())\n        sheet.cell(row=i+1, column=2, value=p.text.strip())\nworkbook.save('TheNew_data.xlsx')\nprint(\"Data has been extracted \")",
        "detail": "DataExtraction",
        "documentation": {}
    }
]